# Jackal deployment and development environment container.
#
# Federico Oliva <lvofrc95@outlook.it>
#
# April 3, 2023

# BUILD THIS WITH:
# --build-arg USER_UID=$UID (if default 1000 causes problems)
# --network host
# RUN THIS WITH:
# --privileged
# --cap-add=SYS_PTRACE
# --network host
# --user ros
# --workdir /home/ros/workspace
# -v ~/.ssh:/home/ros/.ssh
# -v ./config/.aliases.sh:/home/ros/.aliases.sh
# -v ./config/.p10k.zsh:/home/ros/.p10k.zsh
# -v ./config/.ros2_cmds.sh:/home/ros/.ros2_cmds.sh
# -v ./config/.zshrc:/home/ros/.zshrc
# -v ./config/zsh_history:/home/ros/zsh_history
# -v ./config/.bashrc:/home/ros/.bashrc
# -v ./config/.stanis_aliases.sh:/home/ros/.stanis_aliases.sh
# -v /dev:/dev
# -v /sys:/sys
# -v ~/.Xauthority:/home/ros/.Xauthority:rw
# -v ~/.gitconfig:/home/ros/.gitconfig
# -v /etc/localtime:/etc/localtime:ro
# For dev and nvidia targets also add:
# -v ./config/gazebo:/home/ros/.gazebo
# For base targets only add:
# -v ./config/defaults-up.yaml:/home/ros/.colcon/defaults.yaml
# For base-nx targets only add:
# -v .config/defaults-nx.yaml:/home/ros/.colcon/defaults.yaml
# For dev targets only add:
# -v .config/defaults-dev.yaml:/home/ros/.colcon/defaults.yaml
# -v /run/jtop.sock:/run/jtop.sock
# If your terminal emulator supports colors also add:
# --env TERM=xterm-256color
# If you want to start GUI-based applications also add:
# --env="DISPLAY"
# If you use an Nvidia GPU and want to use the Nvidia runtime also add:
# --runtime=nvidia

# Choose the container to build from (see README.md)
ARG TARGET=base
FROM dockoly/jackal:melodic-base
ARG TARGET

ARG USER_UID=1000

# Nvidia GPU architecture version (default: GeForce RTX 3000 series)
# NOTE: You may have to configure this at build time!
ARG CUDA_ARCH_BIN=8.6

# Recompile OpenCV with CUDA support on nvidia targets
RUN \
    if [ "$TARGET" = "nvidia" ]; then \
    cd /opt/opencv && git clean -fdx && \
    cd /opt/opencv_contrib && git clean -fdx && \
    cd /opt/opencv && mkdir build && cd build && \
    cmake \
    -D CMAKE_BUILD_TYPE=RELEASE \
    -D CMAKE_INSTALL_PREFIX=/usr/local \
    -D CUDA_ARCH_BIN="${CUDA_ARCH_BIN}" \
    -D CUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda \
    -D EIGEN_INCLUDE_PATH=/usr/include/eigen3 \
    -D OPENCV_GENERATE_PKGCONFIG=ON \
    -D OPENCV_ENABLE_NONFREE=ON \
    -D OPENCV_EXTRA_MODULES_PATH=/opt/opencv_contrib/modules \
    -D WITH_CUBLAS=ON \
    -D WITH_CUDA=ON \
    -D WITH_CUDNN=ON \
    -D WITH_EIGEN=ON \
    -D WITH_OPENCL=OFF \
    -D WITH_QT=OFF \
    -D WITH_TBB=ON \
    -D WITH_V4L=ON \
    -D ENABLE_FAST_MATH=ON \
    -D CUDA_FAST_MATH=ON \
    -D OPENCV_DNN_CUDA=ON \
    -D BUILD_TBB=ON \
    -D BUILD_EXAMPLES=OFF \
    -D BUILD_TESTS=OFF \
    -D BUILD_opencv_python2=OFF \
    -D BUILD_opencv_python3=ON \
    -D INSTALL_PYTHON_EXAMPLES=OFF \
    -D INSTALL_C_EXAMPLES=OFF \
    -D PYTHON_EXECUTABLE=$(which python2) \
    -D PYTHON3_EXECUTABLE=$(which python3) \
    -D PYTHON3_INCLUDE_DIR=$(python3 -c "from distutils.sysconfig import get_python_inc; print(get_python_inc())") \
    -D PYTHON3_PACKAGES_PATH=$(python3 -c "from distutils.sysconfig import get_python_lib; print(get_python_lib())") \
    .. && \
    make -j$(nproc --all) && \
    make install && \
    ldconfig; \
    yes | pip uninstall opencv-contrib-python && \
    pip install opencv-contrib-python; \
    fi

# Create a non-root sudo user with Zsh as shell
RUN useradd -s /bin/bash --uid $USER_UID -m ros && \
    echo ros ALL=\(root\) NOPASSWD:ALL > /etc/sudoers.d/ros && \
    chmod 0440 /etc/sudoers.d/ros
ENV HOME=/home/ros
RUN chsh -s /usr/bin/zsh ros

# Add new user to system groups
RUN usermod -aG adm ros && \
    usermod -aG dialout ros && \
    usermod -aG plugdev ros && \
    usermod -aG sudo ros && \
    usermod -aG tty ros && \
    usermod -aG video ros

# Create workspace directory: host workspaces will be mounted here
RUN mkdir $HOME/workspace && \
    chown ros $HOME/workspace

# Create shell history and SSH directory for user
RUN mkdir $HOME/zsh_history && \
    chown ros $HOME/zsh_history
RUN mkdir $HOME/.ssh

# Switch to internal user
USER ros
WORKDIR $HOME

# Copy user configuration files
COPY --chown=ros config/.nanorc ./
COPY --chown=ros config/.vimrc ./

# Configure Zsh for internal user
ENV ZSH=$HOME/.oh-my-zsh
ENV ZSH_CUSTOM=$ZSH/custom
RUN wget -qO- https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh | zsh || true
RUN \
    ZSH_PLUGINS=$ZSH_CUSTOM/plugins \
    && ZSH_THEMES=$ZSH_CUSTOM/themes \
    && git clone --single-branch --branch 'master' --depth 1 https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting \
    && git clone --single-branch --branch 'master' --depth 1 https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions \
    && git clone --single-branch --depth 1 https://github.com/romkatv/powerlevel10k.git $ZSH_THEMES/powerlevel10k
COPY --chown=ros config/.zshrc ./
COPY --chown=ros config/.ros2_cmds.sh ./
COPY --chown=ros config/.stanis_aliases.sh ./
COPY --chown=ros config/.aliases.sh ./
COPY --chown=ros config/.p10k.zsh ./

# Configure Bash for internal user
COPY --chown=ros config/.bashrc ./

# If using the ZED SDK, fix some stuff that the installer fucks up
RUN \
    if [ -n "$ZED" ]; then \
    echo "Cleaning up ZED SDK mess..." && \
    sudo chown -R ros /usr/local/zed; \
    fi

# Add image information
LABEL author.name="Federico Oliva"
LABEL author.email="lvofrc95@outlook.it"
LABEL organization="Intelligent Systems Lab"
LABEL description="Jackal rover project $TARGET container"

# Start shell in container
CMD ["zsh"]